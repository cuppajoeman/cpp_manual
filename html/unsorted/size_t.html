<div class="definition" id="definition-size_t">
    The type <code>size_t</code> is an implementation-defined unsigned integer type that is large enough to contain the size in bytes of any object.
</div>

<h2>The Problem with Other Types</h2>
<p>
    Common integer types like <code>int</code> or <code>unsigned int</code> have fixed sizes depending on the platform:
    <ul>
        <li><code>int</code> is usually 32 bits on modern systems, meaning it can store values from <code>-2,147,483,648</code> to <code>2,147,483,647</code>.</li>
        <li><code>unsigned int</code> is also usually 32 bits, allowing values from <code>0</code> to <code>4,294,967,295</code>.</li>
    </ul>
</p>
<p>
    While these ranges are sufficient for most applications, they are not theoretically large enough to represent the size of the largest possible object or array on modern 64-bit systems. 
    For example, a large array with more than the maximum value of <code>unsigned int</code> would make the program have undefined behavior.
</p>

<h2>The Role of <code>size_t</code></h2>
<p>
    <code>size_t</code> is guaranteed to be large enough to represent the size of any object or array in memory. On 64-bit systems, it is typically 64 bits.
</p>
<p>
    Using <code>size_t</code> ensures that:
    <ul>
        <li>Array indices can address all elements in a container safely.</li>
        <li>Values returned by <code>sizeof</code> can represent the size of the largest possible objects.</li>
        <li>Unsigned arithmetic is used, avoiding negative sizes or indices.</li>
    </ul>
</p>

<h2>Conclusion</h2>
<p>
    In summary, <code>size_t</code> exists because other types like <code>int</code> or <code>unsigned int</code> are too small to represent the theoretical maximum object size on some systems. 
    Using these smaller types for sizes or indices could technically fail if objects were large enough, so <code>size_t</code> provides a safe, portable, and standard solution for all memory-related size calculations.
</p>
